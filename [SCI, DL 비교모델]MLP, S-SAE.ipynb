{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pytorch 기반 \n",
    "- MLP 학습 및 평가. SGD(mini batch) 기반 학습\n",
    "- S-SAE 학습 및 평가. optimizer 와 scheduler 까지 활용. \n",
    "    - SAE 먼저 pretrain 하고, encoder 만 떼어냄\n",
    "    - pretrain된 encoder 에 regressor 붙여서 재학습(fine-tuning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import skew\n",
    "from catboost import CatBoostRegressor\n",
    "import gc\n",
    "from sklearn.linear_model import Ridge , LogisticRegression\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor,RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로딩,전처리\n",
    "\n",
    "# 데이터 불러오기 \n",
    "pd.set_option('display.max_columns',100)\n",
    "pd.set_option('display.max_rows',100)\n",
    "file2 = r\"cycletime_minmax.csv\"\n",
    "ct_df = pd.read_csv(file2)\n",
    "ct_df = ct_df.sample(frac=0.01, random_state=42)\n",
    "\n",
    "# x-y 분리, y(타겟) 정규화\n",
    "y_ct = ct_df.iloc[:,-1]\n",
    "x_ct = ct_df.iloc[:,:-1]\n",
    "y_ct = np.log1p(y_ct)\n",
    "\n",
    "# 숫자형/범주형 변수 분리 \n",
    "numerical_list=[]\n",
    "categorical_list=[]\n",
    "\n",
    "for i in x_ct.columns :\n",
    "  if x_ct[i].dtypes == 'O' :\n",
    "    categorical_list.append(i)\n",
    "  else :\n",
    "    numerical_list.append(i)\n",
    "\n",
    "# 범주형 변수 원핫인코딩 \n",
    "x_ct = pd.get_dummies(x_ct, columns=categorical_list, drop_first=True, dtype=int)\n",
    "\n",
    "# 숫자형변수 float32로 통일\n",
    "for col in x_ct.select_dtypes(include=['float64']).columns:\n",
    "    x_ct[col] = x_ct[col].astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥러닝 모델\n",
    "1. MLP\n",
    "2. S-SAE\n",
    "3. (AE) + FCM + BPN \n",
    "4. PCA + K-means + BPN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP \n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, input_size, dropout_prob=0.2):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # Initialize layers\n",
    "        self.linear_1 = torch.nn.Linear(input_size, 600)\n",
    "        self.batch_norm1 = torch.nn.BatchNorm1d(600)\n",
    "\n",
    "        self.linear_2 = torch.nn.Linear(600, 150)\n",
    "        self.batch_norm2 = torch.nn.BatchNorm1d(150)\n",
    "        \n",
    "        self.linear_out = torch.nn.Linear(150, 1)\n",
    "        \n",
    "        # Activation functions\n",
    "        self.leaky_relu = torch.nn.ReLU()\n",
    "        self.dropout = torch.nn.Dropout(dropout_prob)\n",
    "\n",
    "        # Initialize weights using Xavier (Glorot) initialization\n",
    "        torch.nn.init.xavier_uniform_(self.linear_1.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.linear_2.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.linear_out.weight)\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        x = self.dropout(self.leaky_relu(self.batch_norm1(self.linear_1(input_tensor))))\n",
    "        x = self.dropout(self.leaky_relu(self.batch_norm2(self.linear_2(x))))\n",
    "        output = self.linear_out(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu False\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "print(DEVICE,USE_CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "644"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 생성\n",
    "input_dim = x_ct.shape[1]\n",
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼 파라미터 세팅 \n",
    "epochs = 20\n",
    "learning_rate = 0.1\n",
    "BATCH_SIZE = 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 PyTorch 텐서로 변환\n",
    "X_tensor = torch.tensor(x_ct.values, dtype=torch.float32).to(DEVICE)\n",
    "Y_tensor = torch.tensor(y_ct.values, dtype=torch.float32).to(DEVICE).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2917, 1.0000, 0.9300,  ..., 0.0000, 1.0000, 0.0000],\n",
       "        [0.8750, 0.2500, 0.5200,  ..., 1.0000, 0.0000, 0.0000],\n",
       "        [0.6667, 1.0000, 0.8400,  ..., 0.0000, 1.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.5833, 0.0000, 0.6800,  ..., 0.0000, 0.0000, 1.0000],\n",
       "        [0.5833, 0.0000, 0.4300,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [1.0000, 0.2500, 0.0900,  ..., 1.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 학습 데이터와 테스트 데이터로 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, Y_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "# 데이터 로더 생성\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> <class 'torch.utils.data.dataset.TensorDataset'> <class 'torch.utils.data.dataloader.DataLoader'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_tensor), type(train_dataset), type(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([417423, 694]) 417423\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, len(train_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 3.2395\n",
      "Epoch 2, Loss: 0.7638\n",
      "Epoch 3, Loss: 0.6492\n",
      "Epoch 4, Loss: 0.5780\n",
      "Epoch 5, Loss: 0.5245\n"
     ]
    }
   ],
   "source": [
    "# 모델 초기화 및 설정\n",
    "mlp = MLP(input_size=X_train.shape[1]).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.001)\n",
    "\n",
    "# 훈련 루프\n",
    "mlp.train()\n",
    "for epoch in range(5):  # or your choice of number of epochs\n",
    "    running_loss = 0.0\n",
    "    for inputs, targets in train_loader:  # train dataset 6400개 이고, batch size가 64라면 -> 100번의 iteration\n",
    "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        predictions = mlp(inputs)\n",
    "        loss = F.mse_loss(predictions, targets)  # 64개 데이터에 대한 loss값은 1개 ! \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        # 아래 len(train_loader.dataset) 으로 나누기위해 inputs.size(0) 즉, batch size를 곱해주는 것. \n",
    "        # inputs.size(0)을 안곱하면 아래 나눌떄는 len(train_loader.dataset) / inputs.size(0) 만큼을 곱해줄 것. \n",
    "\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.cpu().device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE and MAPE values have been saved to test_results.csv.\n"
     ]
    }
   ],
   "source": [
    "import csv as csv\n",
    "\n",
    "# 평가 루프\n",
    "mlp.eval()\n",
    "with torch.no_grad():\n",
    "    X_test = X_test.to(DEVICE)\n",
    "    predictions = mlp(X_test).cpu()\n",
    "    y_test = y_test.cpu()\n",
    "    individual_mses = (predictions - y_test) ** 2\n",
    "    individual_mapes = torch.abs((predictions - y_test) / y_test) * 100\n",
    "\n",
    "# CSV 파일로 저장\n",
    "def save_to_csv(mses, mapes, filename=\"evaluation_results_MLP.csv\"):\n",
    "    with open(filename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"MSE\", \"MAPE\"])\n",
    "        for mse, mape in zip(mses.numpy().flatten(), mapes.numpy().flatten()):\n",
    "            writer.writerow([mse, mape])\n",
    "\n",
    "save_to_csv(individual_mses, individual_mapes)\n",
    "print(\"MSE and MAPE values have been saved to test_results.csv.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. S-SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "694"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S-SAE 사전학습 \n",
    "\n",
    "class SparseAutoencoder(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SparseAutoencoder, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, 600),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(600, 300),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(300, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 40)  # Bottleneck\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(40, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 300),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(300, 600),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(600, input_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "    def l1_penalty(self, beta):\n",
    "        l1_norm = sum(p.abs().sum() for p in self.encoder.parameters())\n",
    "        return beta * l1_norm\n",
    "\n",
    "# Model instantiation\n",
    "input_size = X_tensor.shape[1] \n",
    "SAE = SparseAutoencoder(input_size).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAEReg(nn.Module):\n",
    "    def __init__(self, encoder, output_size=1):\n",
    "        super(SAEReg, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        # Assuming the encoder's output size (bottleneck) is 40\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(40, output_size)  # Output layer for regression\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        regression_output = self.regressor(encoded)\n",
    "        return regression_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m SAE\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mssae.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Extract the encoder part\u001b[39;00m\n\u001b[0;32m      3\u001b[0m encoder_part \u001b[38;5;241m=\u001b[39m SAE\u001b[38;5;241m.\u001b[39mencoder\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\serialization.py:1462\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[0;32m   1461\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1462\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1465\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_weights_only_unpickler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1466\u001b[0m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1467\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1468\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1469\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1470\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\serialization.py:1964\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1962\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m _serialization_tls\n\u001b[0;32m   1963\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m map_location\n\u001b[1;32m-> 1964\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1965\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1967\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\_weights_only_unpickler.py:512\u001b[0m, in \u001b[0;36mUnpickler.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;28mtype\u001b[39m(pid) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m\n\u001b[0;32m    506\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pid) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mserialization\u001b[38;5;241m.\u001b[39m_maybe_decode_ascii(pid[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    508\u001b[0m     ):\n\u001b[0;32m    509\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(\n\u001b[0;32m    510\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly persistent_load of storage is allowed, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpid[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    511\u001b[0m         )\n\u001b[1;32m--> 512\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpersistent_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpid\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [BINGET[\u001b[38;5;241m0\u001b[39m], LONG_BINGET[\u001b[38;5;241m0\u001b[39m]]:\n\u001b[0;32m    514\u001b[0m     idx \u001b[38;5;241m=\u001b[39m (read(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m key[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m BINGET[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m unpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<I\u001b[39m\u001b[38;5;124m\"\u001b[39m, read(\u001b[38;5;241m4\u001b[39m)))[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\serialization.py:1928\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[1;32m-> 1928\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1929\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1930\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1932\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\serialization.py:1900\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[1;34m(dtype, numel, key, location)\u001b[0m\n\u001b[0;32m   1895\u001b[0m         storage\u001b[38;5;241m.\u001b[39mbyteswap(dtype)\n\u001b[0;32m   1897\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[0;32m   1898\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[0;32m   1899\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[1;32m-> 1900\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   1901\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1902\u001b[0m     _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1903\u001b[0m )\n\u001b[0;32m   1905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typed_storage\u001b[38;5;241m.\u001b[39m_data_ptr() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1906\u001b[0m     loaded_storages[key] \u001b[38;5;241m=\u001b[39m typed_storage\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\serialization.py:693\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    674\u001b[0m \u001b[38;5;124;03mRestores `storage` using a deserializer function registered for the `location`.\u001b[39;00m\n\u001b[0;32m    675\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;124;03m       all matching ones return `None`.\u001b[39;00m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    692\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[1;32m--> 693\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    694\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    695\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\serialization.py:631\u001b[0m, in \u001b[0;36m_deserialize\u001b[1;34m(backend_name, obj, location)\u001b[0m\n\u001b[0;32m    629\u001b[0m     backend_name \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_privateuse1_backend_name()\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(backend_name):\n\u001b[1;32m--> 631\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\serialization.py:600\u001b[0m, in \u001b[0;36m_validate_device\u001b[1;34m(location, backend_name)\u001b[0m\n\u001b[0;32m    598\u001b[0m     device_index \u001b[38;5;241m=\u001b[39m device\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;28;01mif\u001b[39;00m device\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(device_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_available\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m device_module\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m--> 600\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    601\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to deserialize object on a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend_name\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    602\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice but torch.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.is_available() is False. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    603\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you are running on a CPU-only machine, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    604\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    605\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto map your storages to the CPU.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    606\u001b[0m     )\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(device_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice_count\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    608\u001b[0m     device_count \u001b[38;5;241m=\u001b[39m device_module\u001b[38;5;241m.\u001b[39mdevice_count()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "SAE.load_state_dict(torch.load('ssae.pth'))\n",
    "# Extract the encoder part\n",
    "encoder_part = SAE.encoder\n",
    "# Create the SAE with regression model\n",
    "SAEREG = SAEReg(encoder=encoder_part).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, Y_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "# Data loaders\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "# Optimizer and learning schedule\n",
    "optimizer = torch.optim.Adam(SAEREG.parameters(), lr=0.01, weight_decay=1e-7)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=74, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 25\n",
    "learning_rate = 0.07\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sbs\\AppData\\Local\\Temp\\ipykernel_24804\\3721360348.py:8: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = nn.functional.mse_loss(predictions.squeeze(), targets)\n",
      "C:\\Users\\sbs\\AppData\\Local\\Temp\\ipykernel_24804\\3721360348.py:8: UserWarning: Using a target size (torch.Size([143, 1])) that is different to the input size (torch.Size([143])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = nn.functional.mse_loss(predictions.squeeze(), targets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.7703\n",
      "Epoch 2, Loss: 0.7703\n",
      "Epoch 3, Loss: 0.7699\n",
      "Epoch 4, Loss: 0.7701\n",
      "Epoch 5, Loss: 0.7698\n",
      "Epoch 6, Loss: 0.7696\n",
      "Epoch 7, Loss: 0.7696\n",
      "Epoch 8, Loss: 0.7693\n",
      "Epoch 9, Loss: 0.7696\n",
      "Epoch 10, Loss: 0.7693\n",
      "Epoch 11, Loss: 0.7689\n",
      "Epoch 12, Loss: 0.7688\n",
      "Epoch 13, Loss: 0.7691\n",
      "Epoch 14, Loss: 0.7689\n",
      "Epoch 15, Loss: 0.7687\n",
      "Epoch 16, Loss: 0.7688\n",
      "Epoch 17, Loss: 0.7685\n",
      "Epoch 18, Loss: 0.7686\n",
      "Epoch 19, Loss: 0.7687\n",
      "Epoch 20, Loss: 0.7684\n",
      "Epoch 21, Loss: 0.7686\n",
      "Epoch 22, Loss: 0.7685\n",
      "Epoch 23, Loss: 0.7684\n",
      "Epoch 24, Loss: 0.7682\n",
      "Epoch 25, Loss: 0.7684\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m     X_test \u001b[38;5;241m=\u001b[39m X_test\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m     21\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m SAEREG(X_test)\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m---> 22\u001b[0m     mse \u001b[38;5;241m=\u001b[39m (\u001b[43mpredictions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     23\u001b[0m     mape \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mabs((predictions \u001b[38;5;241m-\u001b[39m y_test) \u001b[38;5;241m/\u001b[39m y_test) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Save the results to CSV\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    SAEREG.train()\n",
    "    running_loss = 0.0 \n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        predictions = SAEREG(inputs)\n",
    "        loss = nn.functional.mse_loss(predictions.squeeze(), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    scheduler.step()\n",
    "        \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE and MAPE values have been saved to test_results.csv.\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on test data\n",
    "SAEREG.eval()\n",
    "with torch.no_grad():\n",
    "    X_test = X_test.to(DEVICE)\n",
    "    predictions = SAEREG(X_test).cpu()\n",
    "    y_test = y_test.cpu()\n",
    "    mse = (predictions - y_test) ** 2\n",
    "    mape = torch.abs((predictions - y_test) / y_test) * 100\n",
    "\n",
    "# Save the results to CSV\n",
    "def save_to_csv(mses, mapes, filename=\"evaluation_results_SSAE.csv\"):\n",
    "    with open(filename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"MSE\", \"MAPE\"])\n",
    "        for mse, mape in zip(mses.numpy().flatten(), mapes.numpy().flatten()):\n",
    "            writer.writerow([mse, mape])\n",
    "\n",
    "save_to_csv(mse, mape)\n",
    "print(\"MSE and MAPE values have been saved to test_results.csv.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
